---
title: 'How ChatGPT is becoming more human'
date: 2025-09-16
permalink: /posts/2025/09/blog-post-1/
tags:
  - case study
  - example post
  - ethics
---

The theory behind jailbreaking LLMs 

**News Article reading:**  
[These psychological tricks can get LLMs to respond to “forbidden” prompts](https://arstechnica.com/science/2025/09/these-psychological-tricks-can-get-llms-to-respond-to-forbidden-prompts/)

---
Companies like OpenAI, Google, and Meta have faced criticism in the media over the use of their models for illegal or immoral activities. As a result, they carefully craft system prompts and content filters to curb misuse. However, an article by Ars Technica reports that users are able to bypass these safeguards, a practice known as 'jailbreaking.' 

Large Language Models (LLMs) like ChatGPT are trained on a wealth of texts from real people that model uniquely human biases and behaviors. By using several different persuasion techniques they called Authority, Committment, Liking, Reciprocity, Scarcity, Social Proof, and Unity, researchers at the University of Pennsylvania were able to 'convince' GPT 4o-mini to override it's system prompts and content filters and generate dangerous content.   

Stakeholders:



Why I chose this article:

• The main points of ethical concern from your chosen article in your own words.
• Stakeholder identification, role, and concerns.
• Ethical framework discussion on alignment or conflict with actions with brief reasoning
to your stance. You do not have to mention every ethical framework, but you should
discuss which frameworks align or conflict with the actions taken.
• Brief reflection on how this exercise went for you.



Additional Sources:
- [OpenAI’s flagship AI model has gotten more trustworthy but easier to trick](https://www.theverge.com/2023/10/17/23921501/gpt-4-trust-generative-ai-toxic-bias)
- [ChatGPT’s ‘jailbreak’ tries to make the A.I. break its own rules, or die](https://www.cnbc.com/2023/02/06/chatgpt-jailbreak-forces-it-to-break-its-own-rules.html)
- [We tried out DeepSeek. It worked well, until we asked it about Tiananmen Square and Taiwan](https://www.theguardian.com/technology/2025/jan/28/we-tried-out-deepseek-it-works-well-until-we-asked-it-about-tiananmen-square-and-taiwan)