---
title: 'When the Algorithm Doesn’t Get You'
date: 2025-09-25
permalink: /posts/2025/09/blog-post-3/
tags:
  - case study
  - example post
  - ethics
  - data
---

Sometimes the rules in data don’t fit the people they judge.

**News Article reading:**  
[The Right to Be an Exception to a Data-Driven Rule](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)


In the modern era, algorithms are being used to make decisions that change people's lives, like parole, hiring, or college admissions. However, they make predictions based on averages, and not everyone is average in every way. Data-driven decisions can systemically harm the people who are these exceptions. 

Discussion Questions
---
**What is a data-driven rule, and what does it mean to be a data-driven exception? Is an exception the same as an error?**
A data-driven rule is an algorithm that makes decisions based on data. For us, they can feel like invisible benchmarks that we are being measured against. Data-driven exceptions are people whose circumstances are not adequately captured by the model (the generalization made does not fit them.) Exceptions aren't necessarily errors because in some cases (granting parole) the actual outcome can't be determined. However, in general they are a failure of the model to predict someone because of sampling bias, model capacity, distribution shift, or partial observability. When you're not average, you get missed. 

**In addition to those listed above, what other factors differentiate data-driven decisions from human ones?**
People are able to use discretion when making decisions rather than relying on averages altogether. I liked the example of resume screening because I think this is one that people struggle a lot with recently. If you don't use the correct buzzwords on your resume your resume might be automatically rejected for a job that you were otherwise qualified for. I've had highly qualified friends struggle to get interviews because of Applicant Tracking Software. There is an emphasis on data-driven rules causing systemic harm because people all have different preferences, so standardizing certain features can unfairly disadvantage some people. Additionally, people can generally explain the reason they made a certain decision, but depending on the complexity of a model it may be difficult to interpret why the model made a certain prediction. 

**Beyond what is discussed above, what are some of the benefits and downsides of individualization?**
Individualization is meant to reduce data-driven exceptions by adding more covariates or training data relevant to the decision subject. In my opinion, the hard part would be obtaining enough relevant data. Additionally, the authors bring up the concerns of privacy and the inability of current methods to individualize the way a person would. It would certainly feel creepy if a prospective job had to know my favorite song or animal to decide whether to give me an interview. I would imagine that overfitting would be a bigger problem the more you try and individualize a data-driven rule. 

**Why is uncertainty so critical to the right to be an exception? When the stakes are high (e.g., in criminal sentencing), is there any evaluation metric (e.g., accuracy) that can justify the use of a data-driven rule without the consideration of uncertainty?**
It is critical because there will ALWAYS be uncertainty. Aleatoric uncertainty can't be eliminated. It reminds me of the case where an algorithm was found to exhibit racial bias when making mortgage decisions because it was trained on mortgage application data where black applicants were discriminated against. We don't know what would've happened in their cases because they did not get approved. When the stakes are high, there is no evaluation metric that can justify the use of a data-driven rule without considering uncertainty. 


**If someone is harmed as a result of being a data-driven exception, who is at fault? The person themselves, the company who created the model, the company using the model, or someone else?**
I think this is an important discussion question because they really emphasize in the article that currently people who are data-driven exceptions are carrying the burden the comes with it, and that they shouldn't be. It is important to think about if it is not the responsibility of the person, who is responsible and what steps should they be taking to prevent harm?


### Reflection
Reading this case study reminded me of the examples I've experienced data-driven decisions in my life (jobs, college admissions), and made me consider the situations that I haven't experienced. I tried to approach this in a less academic tone and think about the ways that I could've been a data-driven exception in my life. The case study was very dense so I had to read through it multiple times to really absorb all of the points they were making. I'm still left with a question though, how are people supposed to know they were a data-driven exception? I understand that the authors want the duty to be on data-driven decision makers but I don't see that happening without accountability. 
